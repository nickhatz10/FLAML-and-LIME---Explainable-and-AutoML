# -*- coding: utf-8 -*-
"""SHAP_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gJpNtKWun4nTLTH4J00MgKxT8nh5pHhI
"""

!pip install flaml

!pip install shap

import flaml
from flaml import AutoML
import sklearn
from sklearn.model_selection import train_test_split
import numpy as np
import shap
from sklearn.datasets import fetch_california_housing
import pandas as pd
from google.colab import drive
drive.mount('/content/drive')

housing = pd.read_csv("/content/drive/My Drive/DS 440/housing_fixed.csv")
housing.head()

y = housing.median_house_value

x = housing.drop(["median_house_value","longitude","latitude"], axis = 1)


X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

x.head()

# Initialize an AutoML instance
automl = AutoML()
# Specify automl goal and constraint
automl_settings = {
    "time_budget": 60,  # in seconds
    "metric": 'r2',
    "task": 'regression',
    "log_file_name": "california.log",
}
# Train with labeled input data
automl.fit(X_train=X_train, y_train=y_train,
           **automl_settings)
# Predict
prediction = automl.predict(X_test)
print(prediction)
# Print the best model
print(automl.model.estimator)

#LGBMRegressor(colsample_bytree=0.6782006405163307,learning_rate=0.08222714104485478, max_bin=511, min_child_samples=3, n_estimators=54, num_leaves=283, reg_alpha=0.003934614746573571, reg_lambda=0.003560646472734122, verbose=-1)

!pip install shap

print(automl.model.estimator)

#Changing our output from the automl code to get our model in a normal setting so we can run shap on it freely.
def automl_model_output(automl_model_settings, train_data_x, train_data_y):
  model = automl_model_settings
  model.fit(train_data_x, train_data_y)
  return model

model = automl_model_output(automl.model.estimator, X_train, y_train)

# compute the SHAP values for the linear model
explainer = shap.Explainer(model)
#shap_values = explainer(X_train)

shap.plots.beeswarm(shap_values)

shap_values_test = explainer(X_test)

print(shap_values_test)

shap.plots.beeswarm(shap_values_test)

shap.initjs()
ind = 0
shap.plots.force(shap_values_test[ind])

import ipywidgets as widgets
y.head()



kernel_explainer = shap.KernelExplainer(model = model.predict, data = X_test.head(50), link = "identity")

# print the JS visualization code to the notebook
shap.initjs()

# Create the list of all labels for the drop down list
list_of_labels = X_test.columns.to_list()
#print(list_of_labels)
# Create a list of tuples so that the index of the label is what is returned
tuple_of_labels = list(zip(list_of_labels, range(len(list_of_labels))))
#print(tuple_of_labels)
current_label = widgets.Dropdown(options=tuple_of_labels,
                              value=0,
                              description='Select Label:'
                              )

shap.force_plot(base_value = kernel_explainer.expected_value,
                shap_values = shap_values_test.values[0:5,:],
                features = X_test.iloc[0:50,:]
                )

# print the JS visualization code to the notebook
shap.initjs()


#This waterfall plot is used for looking at exactly one specific row in the dataset.
shap.plots.waterfall(shap_values_test[5])

shap.plots.bar(shap_values_test)