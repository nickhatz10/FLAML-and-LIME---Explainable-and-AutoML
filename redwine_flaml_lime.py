# -*- coding: utf-8 -*-
"""REDWINE_FLAML_LIME

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18JiV-W1qEWmcqfwkGWK0J9QHXDR3sizw
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np

redwine_csv = '/content/drive/My Drive/Capstone/redwine.csv'
redwine_df = pd.read_csv(redwine_csv)
redwine_df

redwine_df.dtypes

# 'axis = 1' corresponds to dropping the column
train_labels = redwine_df['quality']
redwine_df = redwine_df.drop('quality', axis = 1)
train_data = redwine_df

import imblearn
print(imblearn.__version__)

from collections import Counter
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import BorderlineSMOTE
from imblearn.over_sampling import SMOTE
from imblearn.over_sampling import ADASYN
from imblearn.over_sampling import SMOTEN
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

oversample = SMOTE(sampling_strategy = {5: 5000, 6: 5000, 7: 5000, 4: 5000, 8: 5000, 3: 5000})
X_smote, y_smote = oversample.fit_resample(train_data, train_labels)

import matplotlib.pyplot as plt
import seaborn as sns

fig = plt.figure(figsize = (10,6))
sns.countplot(y_smote)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.3, random_state=42)

pip install flaml

# flaml to tune a classifiers hyperparameters

# flaml to find the most accurate classifier
from flaml import AutoML
automl = AutoML()
automl_settings = {"metric": 'accuracy', "task": 'classification'}
#automl.fit(X_train = X_train, y_train = y_train, **automl_settings)
automl.fit(X_train, y_train, **automl_settings)
prediction = automl.predict(X_test)

automl.model

from sklearn.metrics import accuracy_score
accuracy_score(y_test, prediction)

pip install lime

def flaml_lime_classification(train_data, class_names, label_values, index, ml_classifier):
  import lime
  from lime import lime_tabular
  explainer = lime_tabular.LimeTabularExplainer(
    training_data=np.array(train_data),
    feature_names=train_data.columns,
    class_names= class_names,
    mode='classification'
  )

  exp = explainer.explain_instance(data_row=train_data.iloc[index], predict_fn = ml_classifier.predict_proba, labels = label_values)

  return exp.show_in_notebook(show_table=True)

# quality is measured on a scale of 0 - 10
flaml_lime_classification(train_data = X_train, class_names = ['3', '4', '5', '6','7','8'], 
                          label_values = [3,4,5], index = 12, ml_classifier = automl)