# -*- coding: utf-8 -*-
"""SHAP_for_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zT8h6GoNFZfgqcInJpQ9vuCposlfB5ZC
"""

!pip install flaml

!pip install shap

import flaml
from flaml import AutoML
import sklearn
from sklearn.model_selection import train_test_split
import numpy as np
import shap
from sklearn.datasets import fetch_california_housing
import pandas as pd

# mount my google drive to this notebook so I can access my files
from google.colab import drive
drive.mount('/content/drive')

# import statements that we will need for preprocessing
import pandas as pd
import numpy as np

# read csv to turn it into a dataframe
iris_csv = '/content/drive/My Drive/DS 440/iris.csv'
iris_df = pd.read_csv(iris_csv)

# drop the unnecessary ID column
iris_df = iris_df.drop("Id", axis =1)

# replace string labels with integer labels for machine learning
iris_df['Species'] = iris_df['Species'].replace('Iris-setosa', 0)
iris_df['Species'] = iris_df['Species'].replace('Iris-versicolor', 1)
iris_df['Species'] = iris_df['Species'].replace('Iris-virginica', 2)

# get labels and then drop the labels column from the data frame
train_labels = iris_df['Species']
iris_df = iris_df.drop('Species', axis = 1)
train_data = iris_df

# train-test-split to get our training and testing data with train and test labels
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.3, random_state=42)

# flaml to find the most accurate binary classification or multi-class classification classifier
from flaml import AutoML
automl = AutoML()
automl_settings = {"metric": 'accuracy', "task": 'classification', "estimator_list": ['rf']}
automl.fit(X_train.values, y_train.values, **automl_settings)
prediction = automl.predict(X_test.values)

# force plot works for specific data point
# summary plot works for whole datasets
class flaml_shap_classification:

  def __init__(self, model, train_data, test_data):
    self.model = model
    self.train_data = train_data
    self.test_data = test_data

  def summary_plot(self, model_type):
    if model_type == "linear":
      explainer = shap.LinearExplainer(self.model, self.train_data, feature_dependence="independent")

    elif model_type == "tree":
      explainer = shap.TreeExplainer(self.model)

    else:
      explainer = shap.KernelExplainer(self.model.predict_proba, self.train_data)

    shap_values = explainer.shap_values(self.test_data)
    return shap.summary_plot(shap_values, self.test_data)
  

  def force_plot(self, n_samples = 100, index=0, exp_val_ind = 0, shap_first_ind = 0, shap_sec_ind = 0):
 
    explainer = shap.KernelExplainer(self.model.predict_proba, self.train_data)

    shap_values = explainer.shap_values(self.test_data, nsamples = n_samples)
    shap.initjs()
    
    return shap.force_plot(explainer.expected_value[exp_val_ind], shap_values[shap_first_ind][shap_sec_ind], self.test_data.iloc[index])
  

  def force_interactive(self, exp_val_ind = 0, shap_first_ind = 0, shap_sec_ind = 100):
  
    explainer = shap.Explainer(self.model, self.train_data)
    shap_values = explainer.shap_values(self.test_data, check_additivity=False)
    shap.initjs()
    return display(shap.force_plot(explainer.expected_value[exp_val_ind], shap_values[shap_first_ind][:shap_sec_ind], self.test_data))

func1 = flaml_shap_classification(automl.model.estimator, X_train, X_test)
func1.summary_plot('tree')

func2 = flaml_shap_classification(automl.model.estimator, X_train, X_test)
func2.force_plot()

func3 = flaml_shap_classification(automl.model.estimator, X_train, X_test)
func3.force_interactive()